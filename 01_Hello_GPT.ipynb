{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hello GPT\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/1eBcoHjJ2S4G_64sBvYS8G8B-1WSRLQAF?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "\n",
        "By [Ibrahim Sobh](https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/)"
      ],
      "metadata": {
        "id": "cRGFsVRICNgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "jNZy8wMfCQ8M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U6egfDiEdfP",
        "outputId": "7b2daf14-5de9-4b91-df5c-b93307218536"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "17a7aYKQCT5O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLvsgdAqEsqv"
      },
      "source": [
        "from transformers import pipeline, set_seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZQED8WFv1v"
      },
      "source": [
        "gpt2<br>\n",
        "gpt2-medium<br>\n",
        "gpt2-large<br>\n",
        "gpt2-xl<br>\n",
        "distilgpt2<br>\n",
        "microsoft/DialoGPT-small<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load GPT2"
      ],
      "metadata": {
        "id": "wOHKeMjuCXva"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwhSoCcsEsto",
        "outputId": "b432922a-5a0b-48ff-b88c-714c34eb2309"
      },
      "source": [
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate text"
      ],
      "metadata": {
        "id": "ghW00rKvCdRO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4l8sfkQEsxh",
        "outputId": "cfbf66e7-0f9c-4ec9-8feb-8d4824746e63"
      },
      "source": [
        "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)                                                                                      #<|startoftext|>  <|endoftext|>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Hello, I'm a language model, but what I'm really doing is making a human-readable document. There are other languages, but those are\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a syntax model. That's why I like it. I've done a lot of programming projects.\\n\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I'll do it in no time!\\n\\nOne of the things we learned from talking to my friend\"},\n",
              " {'generated_text': \"Hello, I'm a language model, not a command line tool.\\n\\nIf my code is simple enough:\\n\\nif (use (string\"},\n",
              " {'generated_text': \"Hello, I'm a language model, I've been using Language in all my work. Just a small example, let's see a simplified example.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6JdlGnQEs0K",
        "outputId": "06fff383-e3ce-4a69-f975-de4db4fe85f4"
      },
      "source": [
        "generator(\"1,2,3,4,\", max_length=15, num_return_sequences=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '1,2,3,4,5,6,7,8'},\n",
              " {'generated_text': '1,2,3,4,6,7,8,9'},\n",
              " {'generated_text': '1,2,3,4,5,6,7,8'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxJUPTwIEs28",
        "outputId": "0a582b55-e2ac-47ba-9354-0de1c8a0d7ef"
      },
      "source": [
        "generator(\"The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4.\", max_length=35, num_return_sequences=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4. Croatia\\n5. Cyprus\\n6. Finland\\n7.'},\n",
              " {'generated_text': 'The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4. Czech Republic\\n5. Austria-Hungary\\n6.'},\n",
              " {'generated_text': 'The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4. Croatia\\n5. Cyprus\\n6. Czech Republic\\n7'},\n",
              " {'generated_text': 'The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4. Denmark\\n5. Estonia\\n6. Finland\\n7.'},\n",
              " {'generated_text': 'The countries of the European Union are:\\n1. Austria\\n2. Belgium\\n3. Bulgaria\\n4. Croatia\\nFrance, Italy, Germany, Greece etc are:'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhDBy1wxEs7F",
        "outputId": "d53eee62-e8db-481d-d35e-6109409940b4"
      },
      "source": [
        "generator(\"The capital of Japan is Tokyo, The capital of Egypt is\", max_length=13, num_return_sequences=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The capital of Japan is Tokyo, The capital of Egypt is Egypt.'},\n",
              " {'generated_text': 'The capital of Japan is Tokyo, The capital of Egypt is Cairo'},\n",
              " {'generated_text': 'The capital of Japan is Tokyo, The capital of Egypt is Cairo'},\n",
              " {'generated_text': 'The capital of Japan is Tokyo, The capital of Egypt is Cairo'},\n",
              " {'generated_text': 'The capital of Japan is Tokyo, The capital of Egypt is Alexandria'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEJopDcJkXXJ",
        "outputId": "8a81a3a3-dd8c-4087-af24-2330934e91b4"
      },
      "source": [
        "generator(\"1. these are features=this is a feature\\n 2.these are players = this is a\", max_length=25, num_return_sequences=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': '1. these are features=this is a feature\\n 2.these are players = this is a feature\\n\\n3.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeB2_k-7gLBH",
        "outputId": "51fb6966-1585-4dfc-83c3-f3e6ad65167f"
      },
      "source": [
        "generator(\"A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B:\", max_length=40, num_return_sequences=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B: Are you still with the rest of your family? F: This is my mom'},\n",
              " {'generated_text': \"A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B: Sorry I didn't mean to ask you to come by first.\\nB:\"},\n",
              " {'generated_text': 'A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B: Yes.\\nA: How are you? B: Well - well, I'},\n",
              " {'generated_text': \"A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B: Well, as far as I'm concerned, I'm fine, well, well\"},\n",
              " {'generated_text': \"A:Hello\\n B: Hi, how are you?\\nA: I am fine, and you? B: Well, I'm still quite busy.\\nA: The rest are... busy\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPXwSRPjHXje"
      },
      "source": [
        "## Get Features from GPT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KhGXTdyHS-2"
      },
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "model = GPT2Model.from_pretrained('distilgpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFD_XWvCHTDi"
      },
      "source": [
        "text = \"This is a test text.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC3qouGXHTK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d69c5d-7731-45ac-d67c-f608a56f9f63"
      },
      "source": [
        "output[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O-FS5eZ2trs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca92908-cdeb-4cea-d60b-b5f2bfbc5d6d"
      },
      "source": [
        "encoded_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[1212,  318,  257, 1332, 2420,   13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2euPOhGjjk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
