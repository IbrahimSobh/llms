{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Text Assistant\n",
        "\n",
        "🤖 **AI Writing Assistant** to generate text for you, evalaute the generated text and keep ehnacing it, developed based on LangChain, langgraph and gemini llm. The example is for generating attractive post titles about some topic of your choice.\n",
        "\n",
        "By: [Ibrahim Sobh](https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/)\n"
      ],
      "metadata": {
        "id": "DMhqLfXIiDqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "zQthzzH2nhAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xPBHmeviYrG",
        "outputId": "e29ab5e8-a3e7-45af-c94f-8d9ab1934e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U --quiet  langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain-google-genai"
      ],
      "metadata": {
        "id": "kRI1ksK_tXDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "gdcQXk1pnedq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell and paste the API key in the prompt\n",
        "import os\n",
        "import getpass\n",
        "os.environ['GOOGLE_API_KEY'] = getpass.getpass('Gemini API Key:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EHTDv8wvbVJ",
        "outputId": "5ad5d8a7-d77f-4fbb-958b-ac54414e3aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7, top_p=0.85)"
      ],
      "metadata": {
        "id": "eij92i-7ELVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Nodes"
      ],
      "metadata": {
        "id": "Hu_CBQqoGB_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "# generate\n",
        "prompt = PromptTemplate.from_template(\"Tell me a very short title for a facebook post about {subject}.\")\n",
        "gen_chain = prompt | llm"
      ],
      "metadata": {
        "id": "s83YH6ATyp2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate\n",
        "generated_txt = gen_chain.invoke({\"subject\": \"Software testing\"})\n",
        "generated_txt.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9Q1eyhdZyKbQ",
        "outputId": "9f929747-1d64-497e-891c-6f145aca18a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Software Testing: The Unsung Heroes of Quality'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "prompt = PromptTemplate.from_template(\"Evaluate this title {title} to be one of: very good, good or bad\")\n",
        "eval_chain = prompt | llm"
      ],
      "metadata": {
        "id": "Op4nocNlwWMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_score = eval_chain.invoke({\"title\": generated_txt.content})\n",
        "txt_score.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EUHCCaQswWPG",
        "outputId": "f0ce99f6-7bef-4bc1-9e9d-5cbf8a15647d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Very good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhance\n",
        "prompt = PromptTemplate.from_template(\"Rephrase this post title {title} to be a very good title one suitable for social media\")\n",
        "rewrite_chain = prompt | llm"
      ],
      "metadata": {
        "id": "RcuskXQzMctK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_txt = rewrite_chain.invoke({\"title\": generated_txt.content})\n",
        "re_txt.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_UpAeumHM3Pn",
        "outputId": "e264000e-4e24-4bd3-84d6-e07f05538ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Testing: The Secret Weapon in Software's Success Story**\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_chain.invoke({\"title\": generated_txt.content})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4LU3VIDMiE_",
        "outputId": "f66da934-446f-45cc-9328-9ab5e1510dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Very good')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph"
      ],
      "metadata": {
        "id": "zzXq0RKALnBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Dict, TypedDict\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        keys: A dictionary where each key is a string.\n",
        "    \"\"\"\n",
        "\n",
        "    keys: Dict[str, any]"
      ],
      "metadata": {
        "id": "l25agU4VNnr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate txt\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    state_dict = state[\"keys\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "    subject = state_dict[\"subject\"]\n",
        "\n",
        "    res = gen_chain.invoke({\"subject\": subject})\n",
        "\n",
        "    iter = iter+1\n",
        "\n",
        "    return {\"keys\": {\"generation\": res.content, \"subject\":subject ,\"iterations\":iter}}"
      ],
      "metadata": {
        "id": "xDkpNn9RO7NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(state):\n",
        "    \"\"\"\n",
        "    Evaluate txt\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    state_dict = state[\"keys\"]\n",
        "    generated_solution = state_dict[\"generation\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "    subject = state_dict[\"subject\"]\n",
        "\n",
        "    r = eval_chain.invoke({\"title\": generated_solution})\n",
        "\n",
        "    if re.search('very good', r.content, re.IGNORECASE):\n",
        "      error = \"None\"\n",
        "    else:\n",
        "      error = \"FAIL\"\n",
        "\n",
        "    return {\"keys\": {\"generation\": generated_solution,\n",
        "                     \"error\": error,\n",
        "                     \"subject\": subject,\n",
        "                     \"iterations\":iter}}"
      ],
      "metadata": {
        "id": "rB5874FWP45G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rephrase(state):\n",
        "    \"\"\"\n",
        "    Rephrase txt\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "\n",
        "    ## State\n",
        "    state_dict = state[\"keys\"]\n",
        "    generated_solution = state_dict[\"generation\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "    subject = state_dict[\"subject\"]\n",
        "\n",
        "    res = rewrite_chain.invoke({\"title\": generated_solution})\n",
        "    re_txt.content\n",
        "\n",
        "    iter = iter+1\n",
        "    return {\"keys\": {\"generation\": res.content, \"subject\":subject ,\"iterations\":iter}}"
      ],
      "metadata": {
        "id": "sJI921EOQzED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_finish(state):\n",
        "    \"\"\"\n",
        "    Determines whether to finish or re-try\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "    state_dict = state[\"keys\"]\n",
        "    generated_solution = state_dict[\"generation\"]\n",
        "    error = state_dict[\"error\"]\n",
        "    iter = state_dict[\"iterations\"]\n",
        "\n",
        "    print(state)\n",
        "    if error == \"None\":\n",
        "        return \"end\"\n",
        "    else:\n",
        "        return \"rephrase\""
      ],
      "metadata": {
        "id": "h5cyt2eKP477"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"generate\", generate)  # generation initial txt\n",
        "workflow.add_node(\"evaluate\", evaluate)  # evalaute txt\n",
        "workflow.add_node(\"rephrase\", rephrase)  # re-phrase txt\n",
        "\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"generate\")\n",
        "workflow.add_edge(\"generate\", \"evaluate\")\n",
        "workflow.add_edge(\"rephrase\", \"evaluate\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    decide_to_finish,\n",
        "    {\n",
        "        \"end\": END,\n",
        "        \"rephrase\": \"rephrase\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "2E_b1Q-vigG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"recursion_limit\": 200}\n",
        "fina_state = app.invoke({\"keys\":{\"iterations\":0, \"subject\":\"software unit testing\"}},config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jlxEKIiLpZg",
        "outputId": "7e462a0f-684a-4f91-acd1-50cb9cadde6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'keys': {'generation': 'Unit Test: Protect Your Code', 'error': 'FAIL', 'subject': 'software unit testing', 'iterations': 1}}\n",
            "{'keys': {'generation': '🛡️ Unit Test: The Ultimate Defense for Your Code 💪', 'error': 'None', 'subject': 'software unit testing', 'iterations': 2}}\n"
          ]
        }
      ]
    }
  ]
}