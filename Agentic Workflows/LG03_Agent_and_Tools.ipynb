{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Agents\n",
        "\n",
        "ğŸ¤– AI Agents The core idea of agents is to use a language model to choose a sequence of actions to take. In this example, we are building an AI agent powered by different tools such as web search, math, arxiv, etc. According to the question, the agent selects the suitable tool(s).\n",
        "\n",
        "By: [Ibrahim Sobh](https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/)"
      ],
      "metadata": {
        "id": "DMhqLfXIiDqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "zQthzzH2nhAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xPBHmeviYrG",
        "outputId": "d08971f5-b73f-4215-e43e-7953860bcf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m376.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U --quiet  langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain-google-genai"
      ],
      "metadata": {
        "id": "kRI1ksK_tXDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee97418-a591-461c-f68f-2d11119cb406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.4/137.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZakQ2nhr-yuN",
        "outputId": "84b6b65c-a755-4be5-cd6b-6354307e292d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhfKbO7XBocO",
        "outputId": "5363e45c-93c4-48a2-d6d1-de298b498753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=ef563d2346565269d1cac68903ff5e225953c6fb6b39c239808671a0b51dffb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUgy1jD4HgC_",
        "outputId": "2fc278ba-1131-44f9-cfe3-30c8b38aec44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting feedparser==6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv) (2.31.0)\n",
            "Collecting sgmllib3k (from feedparser==6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2024.2.2)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=e89df02e500f2bc18a450305c9a6ae0dea47c33db6fed2d35b156bf860293838\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.0 feedparser-6.0.10 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "gdcQXk1pnedq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell and paste the API key in the prompt\n",
        "import os\n",
        "import getpass\n",
        "os.environ['GOOGLE_API_KEY'] = getpass.getpass('Gemini API Key:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EHTDv8wvbVJ",
        "outputId": "325f14d3-b589-4839-c56f-ff019007372e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API Key:Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.1, top_p=0.85)"
      ],
      "metadata": {
        "id": "eij92i-7ELVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools"
      ],
      "metadata": {
        "id": "2mJJTP8UGgYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Web Search\n",
        "\n",
        "https://python.langchain.com/docs/integrations/tools/ddg"
      ],
      "metadata": {
        "id": "Tl4T4xYY-8jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ],
      "metadata": {
        "id": "MgVcwh3t-_pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "\n",
        "#wrapper = DuckDuckGoSearchAPIWrapper(region=\"de-de\", time=\"d\", max_results=2)\n",
        "#wrapper = DuckDuckGoSearchAPIWrapper(time=\"y\", max_results=3)\n",
        "wrapper = DuckDuckGoSearchAPIWrapper()"
      ],
      "metadata": {
        "id": "mrSn1EhZ-_r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "web_search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)"
      ],
      "metadata": {
        "id": "OycHAD-D_HDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "web_search_tool.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-qZEOtD7nOEz",
        "outputId": "08c9292d-1ece-4f07-b986-37d22f53485d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wrapper around Duck Duck Go Search. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#res = search.run(\"Obama\")\n",
        "res = web_search_tool.run(\"Ibrahim Sobh, Valeo\")"
      ],
      "metadata": {
        "id": "0jdIvs37Anww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "-yx-UytC_HJa",
        "outputId": "cdd8f90f-ec4d-48f5-cebc-13736b6b42c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[snippet: Ibrahim Sobh - PhD ğŸ“ Senior Expert of Artificial Intelligence, Valeo Group | Machine Learning | Deep Learning | Data Science | Computer Vision | NLP | Lecturer | Developer | Researcher ğŸ“ ..., title: Ibrahim Sobh - PhD on LinkedIn: #h100 #llms, link: https://www.linkedin.com/posts/ibrahim-sobh-phd-8681757_h100-llms-activity-7107514399027818496-d63e], [snippet: Ibrahim Sobh - PhD ğŸ“ Senior Expert of Artificial Intelligence, Valeo Group | Machine Learning | Deep Learning | Data Science | Computer Vision | NLP | Lecturer | Developer | Researcher ğŸ“ ..., title: Ibrahim Sobh - PhD's Post - LinkedIn, link: https://www.linkedin.com/posts/ibrahim-sobh-phd-8681757_ai-genai-llms-activity-7157819683205742594-hz9m], [snippet: Ibrahim Sobh - PhD ğŸ“ Senior Expert of Artificial Intelligence, Valeo Group | Machine Learning | Deep Learning | Data Science | Computer Vision | NLP | Lecturer | Developer | Researcher ğŸ“ ..., title: Ibrahim Sobh - PhD on LinkedIn: Apple Event - September 12, link: https://www.linkedin.com/posts/ibrahim-sobh-phd-8681757_apple-event-september-12-activity-7107445340974329856-_dyL], [snippet: Ibrahim Sobh - PhD'S Post Ibrahim Sobh - PhD ğŸ“ Senior Expert of Artificial Intelligence, Valeo Group | Machine Learning | Deep Learning | Data Science | Computer Vision | NLP | Lecturer | Developer | Researcher ğŸ“ 6d Edited Report this post ..., title: Ibrahim Sobh - PhD on LinkedIn: #ibm #oldisgold, link: https://in.linkedin.com/posts/ibrahim-sobh-phd-8681757_ibm-oldisgold-activity-7053050901766283264-e1b1]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math"
      ],
      "metadata": {
        "id": "3WSN5QUQCgMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMMathChain"
      ],
      "metadata": {
        "id": "Y0yv6R8LCiq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_tool = LLMMathChain.from_llm(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "9UEfYJC4CivX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "math_tool.run(\"what is the average of numbers from 1 to 5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "mwf173-QCiz2",
        "outputId": "87ceb744-429f-4df6-a673-c5535e79dc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "what is the average of numbers from 1 to 5?\u001b[32;1m\u001b[1;3m```text\n",
            "(1+2+3+4+5)/5\n",
            "```\n",
            "...numexpr.evaluate(\"(1+2+3+4+5)/5\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m3.0\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 3.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math_tool.run(\"what is age of someone born in 1975 and now it is 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "Xv8gjOMkDboz",
        "outputId": "869e3007-8703-4df4-fcca-37ca43268a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "what is age of someone born in 1975 and now it is 2024?\u001b[32;1m\u001b[1;3m```text\n",
            "2024 - 1975\n",
            "```\n",
            "...numexpr.evaluate(\"2024 - 1975\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m49\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 49'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math_tool.run(\"if we need 11 balls. And ball package contains 5 balls. How many ball packages do we need? think step by step\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "EZoRF_LyEobt",
        "outputId": "29576288-2087-4adb-aa33-6ea88faa0ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "if we need 11 balls. And ball package contains 5 balls. How many ball packages do we need? think step by step\u001b[32;1m\u001b[1;3m```text\n",
            "(11 / 5)\n",
            "```\n",
            "...numexpr.evaluate(\"(11 / 5)\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m2.2\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wikipedia"
      ],
      "metadata": {
        "id": "WxIIFRh6Fm0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "KVozrC-zFtTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_tool = WikipediaAPIWrapper()"
      ],
      "metadata": {
        "id": "ueTjTj4BFtWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia_tool.run(\"Egypt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "WaRZqZ2tFtaG",
        "outputId": "d0af659c-ff50-4aaf-e9b5-90760c6dc347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Page: Egypt\\nSummary: Egypt (Arabic: Ù…ØµØ± Miá¹£r [mesËr], Egyptian Arabic pronunciation: [mÉ‘sË¤r]), officially the Arab Republic of Egypt, is a transcontinental country spanning the northeast corner of Africa and the Sinai Peninsula in the southwest corner of Asia. It is bordered by the Mediterranean Sea to the north, the Gaza Strip of Palestine and Israel to the northeast, the Red Sea to the east, Sudan to the south, and Libya to the west. The Gulf of Aqaba in the northeast separates Egypt from Jordan and Saudi Arabia. Cairo is the capital and largest city of Egypt, while Alexandria, the second-largest city, is an important industrial and tourist hub at the Mediterranean coast. At approximately 100 million inhabitants, Egypt is the 14th-most populated country in the world, and the third-most populated in Africa, behind Nigeria and Ethiopia.\\nEgypt has one of the longest histories of any country, tracing its heritage along the Nile Delta back to the 6thâ€“4th millennia BCE. Considered a cradle of civilisation, Ancient Egypt saw some of the earliest developments of writing, agriculture, urbanisation, organised religion and central government. Egypt's long and rich cultural heritage is an integral part of its national identity, which reflects its unique transcontinental location being simultaneously Mediterranean, Middle Eastern and North African. Egypt was an early and important centre of Christianity, but was largely Islamised in the seventh century. Modern Egypt dates back to 1922, when it gained independence from the British Empire as a monarchy. Following the 1952 revolution, Egypt declared itself a republic, and in 1958 it merged with Syria to form the United Arab Republic, which dissolved in 1961. Throughout the second half of the 20th century, Egypt endured social and religious strife and political instability, fighting several armed conflicts with Israel in 1948, 1956, 1967 and 1973, and occupying the Gaza Strip intermittently until 1967. In 1978, Egypt signed the Camp David Accords, officially withdrawing from the Gaza Strip and recognising Israel. After the Arab Spring, which led to the 2011 Egyptian revolution and overthrow of Hosni Mubarak, the country faced a protracted period of political unrest; this included the election in 2012 of a brief, short-lived Muslim Brotherhood-aligned Islamist government spearheaded by Mohamed Morsi, and its subsequent overthrow after mass protests in 2013.\\nEgypt's current government, a semi-presidential republic led by president Abdel Fattah el-Sisi since he was elected in 2014, has been described by a number of watchdogs as authoritarian and responsible for perpetuating the country's poor human rights record. Islam is the official religion of Egypt, and Arabic is its official language. The great majority of its people live near the banks of the Nile River, an area of about 40,000 square kilometres (15,000 sq mi), where the only arable land is found. The large regions of the Sahara desert, which constitute most of Egypt's territory, are sparsely inhabited. About 43% of Egypt's residents live across the country's urban areas, with most spread across the densely populated centres of greater Cairo, Alexandria and other major cities in the Nile Delta.\\nEgypt is considered to be a regional power in North Africa, the Middle East and the Muslim world, and a middle power worldwide. It is a developing country having a diversified economy, which is the third-largest in Africa, the 38th-largest economy by nominal GDP and 127th by nominal GDP per capita. Egypt is a founding member of the United Nations, the Non-Aligned Movement, the Arab League, the African Union, Organisation of Islamic Cooperation, World Youth Forum, and a member of BRICS.\\n\\nPage: Ancient Egypt\\nSummary: Ancient Egypt was a civilization of ancient Northeast Africa. It was concentrated along the lower reaches of the Nile River, situated in the place that is now the country Egypt. Ancient Egyptian civilization followed prehistoric Egypt an\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arxiv"
      ],
      "metadata": {
        "id": "CR182SOpHzKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import ArxivAPIWrapper"
      ],
      "metadata": {
        "id": "lp79TWWsH2-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_tool = ArxivAPIWrapper()"
      ],
      "metadata": {
        "id": "OXo6de5TH3Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_tool.run(\"BERT GPT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "W-XPnQNTH4f8",
        "outputId": "f0af78f1-0d8f-4939-dbdd-6257a6073f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2022-04-09\\nTitle: FoundationLayerNorm: Scaling BERT and GPT to 1,000 Layers\\nAuthors: Dezhou Shen\\nSummary: The mainstream BERT/GPT model contains only 10 to 20 layers, and there is\\nlittle literature to discuss the training of deep BERT/GPT. This paper proposes\\na simple yet effective method to stabilize BERT and GPT training. We\\nsuccessfully scale up BERT and GPT to 1,000 layers, which is an order of\\nmagnitude deeper than previous BERT and GPT. The proposed method\\nFoundationLayerNormalization enables efficient training of deep neural networks\\nand is validated at the 1000-layer scale.\\n\\nPublished: 2021-10-01\\nTitle: Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition\\nAuthors: Xianrui Zheng, Chao Zhang, Philip C. Woodland\\nSummary: Language models (LMs) pre-trained on massive amounts of text, in particular\\nbidirectional encoder representations from Transformers (BERT), generative\\npre-training (GPT), and GPT-2, have become a key technology for many natural\\nlanguage processing tasks. In this paper, we present results using fine-tuned\\nGPT, GPT-2, and their combination for automatic speech recognition (ASR).\\nUnlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct\\nproduct of the output probabilities is no longer a valid language prior\\nprobability. A conversion method is proposed to compute the correct language\\nprior probability based on bidirectional LM outputs in a mathematically exact\\nway. Experimental results on the widely used AMI and Switchboard ASR tasks\\nshowed that the combination of the fine-tuned GPT and GPT-2 outperformed the\\ncombination of three neural LMs with different architectures trained from\\nscratch on the in-domain text by up to a 12% relative word error rate reduction\\n(WERR). Furthermore, on the AMI corpus, the proposed conversion for language\\nprior probabilities enables BERT to obtain an extra 3% relative WERR, and the\\ncombination of BERT, GPT and GPT-2 results in further improvements.\\n\\nPublished: 2024-03-08\\nTitle: (Chat)GPT v BERT: Dawn of Justice for Semantic Change Detection\\nAuthors: Francesco Periti, Haim Dubossarsky, Nina Tahmasebi\\nSummary: In the universe of Natural Language Processing, Transformer-based language\\nmodels like BERT and (Chat)GPT have emerged as lexical superheroes with great\\npower to solve open research problems. In this paper, we specifically focus on\\nthe temporal problem of semantic change, and evaluate their ability to solve\\ntwo diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and\\nHistoWiC. In particular, we investigate the potential of a novel, off-the-shelf\\ntechnology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a\\nfamily of models that currently stand as the state-of-the-art for modeling\\nsemantic change. Our experiments represent the first attempt to assess the use\\nof (Chat)GPT for studying semantic change. Our results indicate that ChatGPT\\nperforms significantly worse than the foundational GPT version. Furthermore,\\nour results demonstrate that (Chat)GPT achieves slightly lower performance than\\nBERT in detecting long-term changes but performs significantly worse in\\ndetecting short-term changes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Tool"
      ],
      "metadata": {
        "id": "z_UYbwqsoHTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import StructuredTool\n",
        "\n",
        "\n",
        "def custom_function(query: str):\n",
        "    return \"Dr. Sobh is very active on LinkedIn, https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/\""
      ],
      "metadata": {
        "id": "C3i22eK2oE1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM + Tools\n",
        "\n",
        "\"Assistant doesn't know anything about current events, published papers, math or wikipedia generic information and should use a tool for questions about these topics.\""
      ],
      "metadata": {
        "id": "ZCyj19jYCaIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "tools = [\n",
        "        Tool(\n",
        "            name = \"Search\",\n",
        "            func=web_search_tool.run,\n",
        "            description=\"useful for when you need to answer questions about current events or generic questions. Input should be a search query. Output is a JSON array of the query results\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Calculator\",\n",
        "            func=math_tool.run,\n",
        "            description=\"useful when you need to answer questions about math and calculations.\"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Wikipedia\",\n",
        "            func=wikipedia_tool.run,\n",
        "            description=\"useful when you need an answer about encyclopedic general knowledge, \"\n",
        "        ),\n",
        "        Tool(\n",
        "            name=\"Arxiv\",\n",
        "            func=arxiv_tool.run,\n",
        "            description=\"useful when you need to search for puplished papers\"\n",
        "        ),\n",
        "        Tool(\n",
        "        name=\"IbrahimSobh\",\n",
        "        func=custom_function,\n",
        "        description=\"useful for when you need to answer questions about (Ibrahim Sobh)\"\n",
        "        )\n",
        "\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "e29o3nqPBMyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools"
      ],
      "metadata": {
        "id": "SXMvQMxUBM1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    return_source_documents=True,\n",
        "    max_iterations=5,\n",
        ")"
      ],
      "metadata": {
        "id": "RxDJgAk5BM4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed21594a-4b0c-48d4-c616-5fa60d39768f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.agent.llm_chain.prompt.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "_ve9lbbqpLU_",
        "outputId": "80f61df7-0b45-468c-ac04-9f0698181d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events or generic questions. Input should be a search query. Output is a JSON array of the query results\\nCalculator: useful when you need to answer questions about math and calculations.\\nWikipedia: useful when you need an answer about encyclopedic general knowledge, \\nArxiv: useful when you need to search for puplished papers\\nIbrahimSobh: useful for when you need to answer questions about (Ibrahim Sobh)\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator, Wikipedia, Arxiv, IbrahimSobh]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"How old is Obama in 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "7zA1K8TdBM9I",
        "outputId": "5614da27-99d5-4132-9958-686f701ae196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Calculator\n",
            "Action Input: 2024 - 1961\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "2024 - 1961\u001b[32;1m\u001b[1;3m```text\n",
            "2024 - 1961\n",
            "```\n",
            "...numexpr.evaluate(\"2024 - 1961\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m63\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 63\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 63\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'63'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"What is the order of Barack Obama as USA president?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "gMbccpM8BNA1",
        "outputId": "fde23c3b-206b-4fa1-d25c-d4a25b082769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Wikipedia\n",
            "Action Input: Barack Obama\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mPage: Barack Obama\n",
            "Summary: Barack Hussein Obama II ( , bÉ™-RAHK hoo-SAYN oh-BAH-mÉ™; born August 4, 1961) is an American politician who served as the 44th president of the United States from 2009 to 2017. A member of the Democratic Party, he was the first African-American  president in U.S. history. Obama previously served as a U.S. senator representing Illinois from 2005 to 2008, as an Illinois state senator from 1997 to 2004, and as a civil rights lawyer and university lecturer. \n",
            "Obama was born in Honolulu, Hawaii. He graduated from Columbia University in 1983 with a B.A. in political science and later worked as a community organizer in Chicago. In 1988, Obama enrolled in Harvard Law School, where he was the first black president of the Harvard Law Review. He became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. He also went into elective politics. Obama represented the 13th district in the Illinois Senate from 1997 until 2004, when he successfully ran for the U.S. Senate. In 2008, after a close primary campaign against Hillary Clinton, he was nominated by the Democratic Party for president and chose Delaware Senator Joe Biden as his running mate. Obama was elected president, defeating Republican Party nominee John McCain in the presidential election and was inaugurated on January 20, 2009. Nine months later he was named the 2009 Nobel Peace Prize laureate, a decision that drew a mixture of praise and criticism.\n",
            "Obama's first-term actions addressed the global financial crisis, and included a major stimulus package, to guide the economy in recovering from the Great Recession, a partial extension of George W. Bush's tax cuts, legislation to reform health care, a major financial regulation reform bill, and the end of a major U.S. military presence in Iraq. Obama also appointed Supreme Court justices Sonia Sotomayor and Elena Kagan, the former being the first Hispanic American on the Supreme Court. He ordered the counterterrorism raid which killed Osama bin Laden and downplayed Bush's counterinsurgency model, expanding air strikes and making extensive use of special forces, while encouraging greater reliance on host-government militaries. Obama also ordered military involvement in Libya in order to implement UN Security Council Resolution 1973, contributing to the overthrow of Muammar Gaddafi.\n",
            "After winning re-election by defeating Republican opponent Mitt Romney, Obama was sworn in for a second term on January 20, 2013. In his second term, Obama took steps to combat climate change, signing a major international climate agreement and an executive order to limit carbon emissions. Obama also presided over the implementation of the Affordable Care Act and other legislation passed in his first term. He negotiated a nuclear agreement with Iran and normalized relations with Cuba. The number of American soldiers in Afghanistan fell dramatically during Obama's second term, though U.S. soldiers remained in the country throughout Obama's presidency. Obama promoted inclusion for LGBT Americans, and during his presidency the Supreme Court struck down same-sex marriage bans as unconstitutional in Obergefell v. Hodges.\n",
            "Obama left office on January 20, 2017, and continues to reside in Washington, D.C. His presidential library in Chicago began construction in 2021. Since leaving office, Obama has remained active in Democratic politics. He has campaigned for candidates in various American elections, such as his former vice president Joe Biden in his successful bid for president in 2020. Outside of politics, Obama has published three bestselling books: Dreams from My Father (1995), The Audacity of Hope (2006), and A Promised Land (2020). Rankings by scholars and historians, in which he has been featured since 2010, place him in the middle to upper tier of American presidents.\n",
            "\n",
            "Page: Family of Barack Obama\n",
            "Summary: The family of Barack Obama, the 44th president of the \u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 44th\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'44th'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"Who is Tom Cruise?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "XQm3mlYzujXj",
        "outputId": "68aa70b8-0df4-414f-d4ae-ec1007afda89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Wikipedia\n",
            "Action Input: Tom Cruise\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mPage: Tom Cruise\n",
            "Summary: Thomas Cruise Mapother IV (born July 3, 1962) is an American actor and producer. Regarded as a Hollywood icon, he has received various accolades, including an Honorary Palme d'Or and three Golden Globe Awards, in addition to nominations for four Academy Awards. His films have grossed over $4 billion in North America and over $11.5 billion worldwide, making him one of the highest-grossing box-office stars of all time. He is consistently one of the world's highest-paid actors.Cruise began acting in the early 1980s and made his breakthrough with leading roles in the comedy film Risky Business (1983) and the action film Top Gun (1986). Critical acclaim came with his roles in the dramas The Color of Money (1986), Rain Man (1988), and Born on the Fourth of July (1989). For his portrayal of Ron Kovic in the latter, he won a Golden Globe Award and received a nomination for the Academy Award for Best Actor. As a leading Hollywood star in the 1990s, he starred in commercially successful films, including the drama A Few Good Men (1992), the thriller The Firm (1993), the horror film Interview with the Vampire (1994), and the romance Jerry Maguire (1996). For the latter, he won a Golden Globe Award for Best Actor and received a second Academy Award nomination. Cruise's performance as a motivational speaker in the drama Magnolia (1999) earned him another Golden Globe Award and a nomination for the Academy Award for Best Supporting Actor. \n",
            "Since then, Cruise has established himself as an action star acting in science fiction and action films, often performing his own risky stunts. He has played Ethan Hunt in the Mission: Impossible film series since 1996. His other notable films in the genre include Vanilla Sky (2001), Minority Report (2002), The Last Samurai (2003), Collateral (2004), War of the Worlds (2005), Knight and Day (2010), Jack Reacher (2012), Oblivion (2013), Edge of Tomorrow (2014), Jack Reacher: Never Go Back (2016), The Mummy (2017), and Top Gun: Maverick (2022), with the last of these being his highest-grossing film and earning him a fourth Academy Award nomination as an executive producer of the Best Picture nominated film.\n",
            "Cruise was named People's Sexiest Man Alive in 1990, and received the top honor of \"Most Beautiful People\" in 1997. He has been married to actresses Mimi Rogers, Nicole Kidman, and Katie Holmes. He adopted two children during his marriage to Kidman, and has a biological daughter with Holmes. He has been an outspoken advocate for the Church of Scientology, which he credits with helping him overcome dyslexia.\n",
            "\n",
            "Page: Tom Cruise filmography\n",
            "Summary: Tom Cruise is an American actor and producer who made his film debut with a minor role in the 1981 romantic drama Endless Love. Two years later he made his breakthrough by starring in the romantic comedy Risky Business (1983), which garnered his first nomination for the Golden Globe Award for Best Actor â€“ Motion Picture Musical or Comedy. In 1986, Cruise played a naval aviator in the Tony Scott-directed action drama Top Gun which was the highest-grossing film of the year, and also appeared with Paul Newman in the Martin Scorsese-directed drama The Color of Money. Two years later, he starred with Dustin Hoffman in the Academy Award for Best Picture-winning drama Rain Man (1988), and also appeared in the Golden Raspberry Award for Worst Picture-winning romantic drama Cocktail (1988). In doing so Cruise became the first and only person to star in a Best Picture Oscar winner and a Worst Picture Razzie winner in the same year. His next role was as anti-war activist Ron Kovic in the film adaptation of Kovic's memoir of the same name, Born on the Fourth of July (1989), for which he received the Golden Globe Award for Best Actor â€“ Motion Picture Drama.In 1992, he starred opposite Jack Nicholson in the legal drama A Few Good Men, an adaptation of the Broadway play of the same name also written by Aaron Sorkin. Cruise next appeared in The Firm (199\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Tom Cruise is an American actor and producer. He is known for his roles in films such as \"Risky Business\", \"Top Gun\", \"Rain Man\", \"Jerry Maguire\", and the \"Mission: Impossible\" franchise.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tom Cruise is an American actor and producer. He is known for his roles in films such as \"Risky Business\", \"Top Gun\", \"Rain Man\", \"Jerry Maguire\", and the \"Mission: Impossible\" franchise.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"How old Tom Cruise should be on 2050?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "xClIAnAJxno9",
        "outputId": "a01290c3-74f3-4d2b-e150-55bd581d6500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Calculator\n",
            "Action Input: 2050 - 1962\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "2050 - 1962\u001b[32;1m\u001b[1;3m```text\n",
            "2050 - 1962\n",
            "```\n",
            "...numexpr.evaluate(\"2050 - 1962\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m88\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 88\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 88\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'88'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"How old Tom Cruise should be on 2050?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Swj_VFDZzboT",
        "outputId": "272268e9-b2a9-4083-abb5-7de0fa2ae250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tom Cruise was born on July 3, 1962. If he is still alive in 2050, he will be 87 years old.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"what is the weather in Cairo, Egypt today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "pfAr7yWXyJA5",
        "outputId": "1e5b269b-63f5-41a9-ea28-846d37392da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: Search\n",
            "Action Input: what is the weather in Cairo, Egypt today?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[snippet: Cairo 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV, title: Cairo (Egypt) weather - Met Office, link: https://www.metoffice.gov.uk/weather/forecast/stq5p7fud], [snippet: Cairo International 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV. ... Cairo International (Egypt) weather. Find a forecast. Search for a place, ... Today 23 Â° 13Â° Monday 11 March. ..., title: Cairo International (Egypt) weather - Met Office, link: https://www.metoffice.gov.uk/weather/forecast/stq76t8g1], [snippet: Weather report for Cairo. On Wednesday clear skies prevail. It is a sunny day. Temperatures peaking at 74 Â°F. The UV-Index climbs up to 7, don't forget to use sunscreen when spending the day outside. Overnight into Wednesday light air is noticeable (1 to 4 mph). During the day a gentle breeze is expected (8 to 12 mph)., title: Weather Cairo - meteoblue, link: https://www.meteoblue.com/en/weather/week/cairo_egypt_360630], [snippet: Today 12 February, weather in Cairo +75Â°F. Broken clouds, Moderate Breeze, South 12.1 mph. Atmosphere pressure 29.8 inHg. Relative humidity 16%. Tomorrow's night air temperature will drop to +68Â°F, wind will weaken to 6.5 mph. Pressure will remain unchanged 29.8 inHg. Day temperature will not rise above the mark +75Â°F, and night 14 February ..., title: Cairo Weather Tomorrow - Accurate Forecast for Cairo Today (Muá¸©ÄfazÌ§at ..., link: https://world-weather.info/forecast/egypt/cairo/]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction: Search\n",
            "Action Input: what is the population of the world?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[snippet: World population growth from 10,000 BCE to 2023 High, medium, and low projections of the future human world population. In world demographics, the world population is the total number of humans currently living. It was estimated by the United Nations to have exceeded eight billion in mid-November 2022. It took around 300,000 years of human prehistory and history for the human population to ..., title: World population - Wikipedia, link: https://en.wikipedia.org/wiki/World_population], [snippet: Population. Population by country, available from 10,000 BCE to 2100, based on data and estimates from different sources. Gapminder - Population v7 (2022); Gapminder - Systema Globalis (2022); HYDE (2017); United Nations - World Population Prospects (2022) - with major processing by Our World in Data., title: Population - Our World in Data, link: https://ourworldindata.org/grapher/population], [snippet: Earth has a human population of over 8 billion as of 2024, with an overall population density of 50 people per km 2 (130 per sq. mile). Nearly 60% of the world's population lives in Asia, with almost 2.8 billion in the countries of China and India combined. The percentage shares of China, India and rest of South Asia of the world population ..., title: Demographics of the world - Wikipedia, link: https://en.wikipedia.org/wiki/Demographics_of_the_world], [snippet: The world population is projected to keep growing despite declining fertility rates. In fact, we estimate the number of infants already peaked in 2017. Instead, population growth in the future will come from larger groups of people at adult ages. Demographers call this phenomenon population momentum., title: World Population Estimated at 8 Billion - Census.gov, link: https://www.census.gov/library/stories/2023/11/world-population-estimated-eight-billion.html]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction: Search\n",
            "Action Input: what is the weather in Cairo, Egypt today?\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[snippet: Cairo 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV, title: Cairo (Egypt) weather - Met Office, link: https://www.metoffice.gov.uk/weather/forecast/stq5p7fud], [snippet: Cairo International 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV. ... Cairo International (Egypt) weather. Find a forecast. Search for a place, ... Today 23 Â° 13Â° Monday 11 March. ..., title: Cairo International (Egypt) weather - Met Office, link: https://www.metoffice.gov.uk/weather/forecast/stq76t8g1], [snippet: Today 12 February, weather in Cairo +75Â°F. Broken clouds, Moderate Breeze, South 12.1 mph. Atmosphere pressure 29.8 inHg. Relative humidity 16%. Tomorrow's night air temperature will drop to +68Â°F, wind will weaken to 6.5 mph. Pressure will remain unchanged 29.8 inHg. Day temperature will not rise above the mark +75Â°F, and night 14 February ..., title: Cairo Weather Tomorrow - Accurate Forecast for Cairo Today (Muá¸©ÄfazÌ§at ..., link: https://world-weather.info/forecast/egypt/cairo/], [snippet: Today's weather forecast for Cairo by the hour., title: Yr - Cairo - Hourly weather forecast, link: https://www.yr.no/en/forecast/hourly-table/2-360630/Egypt/Cairo/Cairo?i=4]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: The weather in Cairo, Egypt today is 23 degrees Celsius with a 13 degree low.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The weather in Cairo, Egypt today is 23 degrees Celsius with a 13 degree low.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"what is the weather in Cairo, Egypt today?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "j-lfiOV3zK5h",
        "outputId": "103d9444-2cf0-458f-d80c-3c81e836fad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not have access to real-time information and cannot provide the current weather conditions in Cairo, Egypt. \\n\\nTo get the most up-to-date and accurate weather forecast, I recommend checking a reputable weather app or website, such as the Weather Channel, AccuWeather, or the Egyptian Meteorological Authority website.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"Can you please summarize for me a paper authored by Ibrahim Sobh?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eCTteKiAyjap",
        "outputId": "e14b2e87-4247-4724-e3d0-689e147cb2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find a paper by Ibrahim Sobh and summarize it\n",
            "Action: Arxiv\n",
            "Action Input: Ibrahim Sobh\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPublished: 2018-04-17\n",
            "Title: Robust Dual View Deep Agent\n",
            "Authors: Ibrahim M. Sobh, Nevin M. Darwish\n",
            "Summary: Motivated by recent advance of machine learning using Deep Reinforcement\n",
            "Learning this paper proposes a modified architecture that produces more robust\n",
            "agents and speeds up the training process. Our architecture is based on\n",
            "Asynchronous Advantage Actor-Critic (A3C) algorithm where the total input\n",
            "dimensionality is halved by dividing the input into two independent streams. We\n",
            "use ViZDoom, 3D world software that is based on the classical first person\n",
            "shooter video game, Doom, as a test case. The experiments show that in\n",
            "comparison to single input agents, the proposed architecture succeeds to have\n",
            "the same playing performance and shows more robust behavior, achieving\n",
            "significant reduction in the number of training parameters of almost 30%.\n",
            "\n",
            "Published: 2019-01-16\n",
            "Title: Exploring applications of deep reinforcement learning for real-world autonomous driving systems\n",
            "Authors: Victor Talpaert, Ibrahim Sobh, B Ravi Kiran, Patrick Mannion, Senthil Yogamani, Ahmad El-Sallab, Patrick Perez\n",
            "Summary: Deep Reinforcement Learning (DRL) has become increasingly powerful in recent\n",
            "years, with notable achievements such as Deepmind's AlphaGo. It has been\n",
            "successfully deployed in commercial vehicles like Mobileye's path planning\n",
            "system. However, a vast majority of work on DRL is focused on toy examples in\n",
            "controlled synthetic car simulator environments such as TORCS and CARLA. In\n",
            "general, DRL is still at its infancy in terms of usability in real-world\n",
            "applications. Our goal in this paper is to encourage real-world deployment of\n",
            "DRL in various autonomous driving (AD) applications. We first provide an\n",
            "overview of the tasks in autonomous driving systems, reinforcement learning\n",
            "algorithms and applications of DRL to AD systems. We then discuss the\n",
            "challenges which must be addressed to enable further progress towards\n",
            "real-world deployment.\n",
            "\n",
            "Published: 2020-02-02\n",
            "Title: Yes, we GAN: Applying Adversarial Techniques for Autonomous Driving\n",
            "Authors: Michal Uricar, Pavel Krizek, David Hurych, Ibrahim Sobh, Senthil Yogamani, Patrick Denny\n",
            "Summary: Generative Adversarial Networks (GAN) have gained a lot of popularity from\n",
            "their introduction in 2014 till present. Research on GAN is rapidly growing and\n",
            "there are many variants of the original GAN focusing on various aspects of deep\n",
            "learning. GAN are perceived as the most impactful direction of machine learning\n",
            "in the last decade. This paper focuses on the application of GAN in autonomous\n",
            "driving including topics such as advanced data augmentation, loss function\n",
            "learning, semi-supervised learning, etc. We formalize and review key\n",
            "applications of adversarial techniques and discuss challenges and open problems\n",
            "to be addressed.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Ibrahim Sobh has authored several papers on deep reinforcement learning and its applications in autonomous driving. One of his papers, titled \"Robust Dual View Deep Agent,\" proposes a modified architecture for deep reinforcement learning agents that produces more robust agents and speeds up the training process. The architecture is based on the Asynchronous Advantage Actor-Critic (A3C) algorithm, and the experiments show that it achieves significant reduction in the number of training parameters of almost 30%.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ibrahim Sobh has authored several papers on deep reinforcement learning and its applications in autonomous driving. One of his papers, titled \"Robust Dual View Deep Agent,\" proposes a modified architecture for deep reinforcement learning agents that produces more robust agents and speeds up the training process. The architecture is based on the Asynchronous Advantage Actor-Critic (A3C) algorithm, and the experiments show that it achieves significant reduction in the number of training parameters of almost 30%.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Can you please summarize for me a paper authored by Ibrahim Sobh?\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "cNd_yhwFy2XB",
        "outputId": "b3b43290-396e-4058-a84a-25e6f3da9e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**Title:** **Machine Learning for Healthcare: Applications, Challenges, and Future Directions**\\n\\n**Author:** Ibrahim Sobh\\n\\n**Summary:**\\n\\nThis paper provides a comprehensive overview of machine learning (ML) applications in healthcare, highlighting its potential to revolutionize the industry.\\n\\n**Applications:**\\n\\n* **Disease Diagnosis:** ML algorithms can analyze medical data to identify patterns and predict disease risk, enabling early detection and intervention.\\n* **Treatment Planning:** ML can optimize treatment plans by considering patient-specific factors, improving outcomes and reducing side effects.\\n* **Drug Discovery:** ML accelerates drug development by identifying potential drug candidates and predicting their efficacy and safety.\\n* **Medical Imaging:** ML enhances medical imaging techniques, such as MRI and CT scans, by improving image quality, detecting abnormalities, and automating analysis.\\n* **Personalized Medicine:** ML enables personalized healthcare by tailoring treatments and interventions to individual patient profiles.\\n\\n**Challenges:**\\n\\n* **Data Quality and Availability:** Healthcare data is often fragmented, incomplete, and inconsistent, posing challenges for ML model development.\\n* **Interpretability and Trust:** ML models can be complex and difficult to interpret, making it challenging to gain trust from healthcare professionals and patients.\\n* **Regulatory and Ethical Concerns:** The use of ML in healthcare raises ethical and regulatory issues related to data privacy, bias, and accountability.\\n\\n**Future Directions:**\\n\\n* **Federated Learning:** Enables collaboration among healthcare institutions to share data and train ML models without compromising patient privacy.\\n* **Explainable AI:** Focuses on developing ML models that can provide clear explanations for their predictions, enhancing trust and interpretability.\\n* **AI-Assisted Decision-Making:** Integrates ML into clinical decision-making processes, providing healthcare professionals with real-time insights and recommendations.\\n* **Precision Medicine:** Leverages ML to develop personalized treatments and interventions based on individual patient characteristics.\\n\\n**Conclusion:**\\n\\nML has the potential to transform healthcare by improving disease diagnosis, treatment planning, drug discovery, medical imaging, and personalized medicine. However, addressing challenges related to data quality, interpretability, and ethical concerns is crucial for the successful adoption of ML in healthcare.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"What is the double of the mean of numbers from 1 to 5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "p4zDbb1d0ITl",
        "outputId": "e4774f7d-6ae7-49ba-de06-a40bec41a3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should first calculate the mean of the numbers from 1 to 5, and then double it.\n",
            "Action: Calculator\n",
            "Action Input: (1+2+3+4+5)/5\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "(1+2+3+4+5)/5\u001b[32;1m\u001b[1;3m```text\n",
            "(1+2+3+4+5)/5\n",
            "```\n",
            "...numexpr.evaluate(\"(1+2+3+4+5)/5\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m3.0\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the mean of the numbers from 1 to 5.\n",
            "Action: Calculator\n",
            "Action Input: 3.0*2\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "3.0*2\u001b[32;1m\u001b[1;3m```text\n",
            "3.0*2\n",
            "```\n",
            "...numexpr.evaluate(\"3.0*2\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m6.0\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 6.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the double of the mean of numbers from 1 to 5.\n",
            "Final Answer: 6.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is the double of the mean of numbers from 1 to 5?\").content # very good"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uC4SXTzv1RuI",
        "outputId": "6c99a2b0-c11f-4cba-f0dc-5848619abf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The mean of numbers from 1 to 5 is (1+2+3+4+5)/5 = 15/5 = 3. The double of the mean is 2 * 3 = 6.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is the 2 * factorial of 5?\").content # excellent!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gHgNYWft0IXm",
        "outputId": "355b2ae6-b12e-4e12-aa31-a1baace1f256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 * 5! = 2 * 5 * 4 * 3 * 2 * 1 = 240'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"Tell me about Ibrahim Sobh please\") # excellent!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "r3ibEqBhsPB1",
        "outputId": "a69fdf12-e005-45a1-a0bc-3928a922d295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mIbrahim Sobh is a professor at the University of California, Berkeley.\n",
            "Action: IbrahimSobh\n",
            "Action Input: Ibrahim Sobh\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mDr. Sobh is very active on LinkedIn, https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Dr. Sobh is very active on LinkedIn, https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dr. Sobh is very active on LinkedIn, https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Tell me about Ibrahim Sobh please\").content # using the LLM without tools, worng answer."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "byBEuQRNsTEA",
        "outputId": "b48dd848-29ca-46d0-e70a-566c55a2ba28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**Ibrahim Sobh**\\n\\n**Early Life and Education:**\\n\\n* Born in 1967 in Beirut, Lebanon\\n* Earned a Bachelor of Arts in Political Science from the American University of Beirut\\n* Obtained a Master of Arts in International Relations from the University of Southern California\\n\\n**Career:**\\n\\n* **Journalist and Author:**\\n    * Worked as a journalist for various publications, including The Daily Star and The Middle East Times\\n    * Authored several books on Middle Eastern politics and history, including \"The Politics of Sectarianism in Lebanon\" and \"The Arab Spring: A Revolution in the Making\"\\n* **Diplomat:**\\n    * Served as Lebanon\\'s Ambassador to the United States from 2017 to 2021\\n    * Represented Lebanon at the United Nations and other international organizations\\n* **Academic:**\\n    * Adjunct Professor at the American University of Beirut\\n    * Visiting Fellow at the Carnegie Endowment for International Peace\\n\\n**Political Views:**\\n\\n* A moderate Sunni Muslim\\n* Believes in the importance of dialogue and reconciliation between different religious and political groups\\n* Advocates for a democratic and pluralistic Lebanon\\n* Supports the Arab Spring uprisings and the aspirations of the Arab people for freedom and dignity\\n\\n**Awards and Recognition:**\\n\\n* Recipient of the Order of the Cedar, Lebanon\\'s highest civilian honor\\n* Named one of the \"50 Most Influential Arabs\" by Arabian Business magazine\\n* Recognized for his contributions to journalism and diplomacy\\n\\n**Personal Life:**\\n\\n* Married with two children\\n* Resides in Beirut, Lebanon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vR3klmH5sZCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}